#
import matplotlib.pyplot as plt
import numpy as np
#
#
#
LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data =  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 100.0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 100.0, 0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 100.0, 0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 100.0, 0, 0, 0, 0, 100.0, 0, 0, 100.0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 50.0, 100.0, 100.0, 100.0, 100.0, 0, 100.0, 100.0, 0, 0, 100.0, 100.0, 100.0, 100.0, 0, 100.0, 100.0, 100.0, 100.0, 100.0, 0.0, 100.0, 100.0, 0, 100.0, 100.0, 100.0, 55.55555555555556, 100.0, 100.0, 0.0, 50.0, 100.0, 75.0, 100.0, 33.333333333333336, 25.0, 50.0, 66.66666666666667, 50.0, 100.0, 33.333333333333336, 60.0, 40.0, 50.0, 100.0, 50.0, 28.571428571428573, 40.0, 66.66666666666667, 0.0, 42.857142857142854, 66.66666666666667, 16.666666666666668, 42.857142857142854, 12.5, 50.0, 100.0, 0.0, 37.5, 0.0, 9.090909090909092, 44.44444444444444, 11.11111111111111, 0.0, 10.0, 6.25, 11.11111111111111, 44.44444444444444, 0.0, 5.0, 7.6923076923076925, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 8.695652173913043, 3.8461538461538463, 0.0, 0.0, 6.666666666666667, 4.3478260869565215, 0.0, 5.405405405405405, 3.225806451612903, 0.0, 0.0, 0.0, 16.0, 12.195121951219512, 0.0, 0.0, 0.0, 3.4482758620689653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
#
NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data =  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 100.0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 100.0, 0, 0, 0, 0, 100.0, 0, 100.0, 100.0, 0, 0, 0, 0, 0, 0, 100.0, 0, 100.0, 0, 100.0, 0, 0, 0, 0, 0, 100.0, 100.0, 100.0, 0, 100.0, 0, 0, 0, 0, 100.0, 0, 0, 100.0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 0, 100.0, 100.0, 100.0, 0, 100.0, 100.0, 100.0, 100.0, 100.0, 0, 100.0, 66.66666666666667, 0, 0, 100.0, 100.0, 100.0, 100.0, 0, 100.0, 100.0, 100.0, 100.0, 100.0, 0.0, 16.666666666666668, 100.0, 0, 0.0, 50.0, 50.0, 0.0, 100.0, 0.0, 0.0, 100.0, 100.0, 25.0, 0.0, 33.333333333333336, 0.0, 0.0, 33.333333333333336, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 66.66666666666667, 0.0, 0.0, 40.0, 50.0, 0.0, 0.0, 33.333333333333336, 16.666666666666668, 0.0, 25.0, 0.0, 14.285714285714286, 0.0, 12.5, 14.285714285714286, 9.090909090909092, 44.44444444444444, 22.22222222222222, 0.0, 0.0, 6.25, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.225806451612903, 0.0, 0.0, 0.0, 0.0, 2.4390243902439024, 0.0, 2.0, 2.2222222222222223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8097165991902834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
#
#
list_top_probabilities_of_classes_from_least_to_most_likely_in_training = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.002261420171867933, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.004522840343735866, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.0067842605156037995, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.009045680687471733, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.011307100859339666, 0.013568521031207599, 0.013568521031207599, 0.013568521031207599, 0.013568521031207599, 0.013568521031207599, 0.013568521031207599, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.015829941203075532, 0.018091361374943465, 0.018091361374943465, 0.018091361374943465, 0.0203527815468114, 0.0203527815468114, 0.0203527815468114, 0.0203527815468114, 0.022614201718679332, 0.022614201718679332, 0.022614201718679332, 0.022614201718679332, 0.024875621890547265, 0.024875621890547265, 0.024875621890547265, 0.027137042062415198, 0.027137042062415198, 0.027137042062415198, 0.02939846223428313, 0.02939846223428313, 0.031659882406151064, 0.031659882406151064, 0.033921302578018994, 0.033921302578018994, 0.03618272274988693, 0.03618272274988693, 0.03618272274988693, 0.03618272274988693, 0.03618272274988693, 0.03618272274988693, 0.03844414292175486, 0.0407055630936228, 0.0407055630936228, 0.04296698326549073, 0.04296698326549073, 0.045228403437358664, 0.045228403437358664, 0.05201266395296246, 0.054274084124830396, 0.054274084124830396, 0.056535504296698326, 0.06105834464043419, 0.06105834464043419, 0.06331976481230213, 0.06558118498417007, 0.06558118498417007, 0.06558118498417007, 0.07010402532790593, 0.07010402532790593, 0.07236544549977386, 0.07688828584350972, 0.07914970601537766, 0.07914970601537766, 0.09271822704658525, 0.09271822704658525, 0.09271822704658525, 0.09724106739032112, 0.10176390773405698, 0.10402532790592492, 0.10854816824966079, 0.11985526910900045, 0.12890094979647218, 0.13116236996834013, 0.13794663048394393, 0.14473089099954772, 0.14699231117141565, 0.1560379918588874, 0.16056083220262324, 0.1650836725463591, 0.16734509271822703, 0.16960651289009498, 0.1718679330619629, 0.1854364540931705, 0.20578923563998192, 0.24423337856173677, 0.25780189959294436, 0.2645861601085482, 0.2939846223428313, 0.3007688828584351, 0.30303030303030304, 0.3143374038896427, 0.3143374038896427, 0.33242876526458615, 0.4228855721393035, 0.4681139755766621, 0.48846675712347354, 0.5789235639981909, 0.7146087743102668, 0.74400723654455, 0.7734056987788331, 0.8005427408412483, 1.1623699683401176, 1.5513342379014021, 1.9448213478064225, 2.254635911352329, 2.365445499773858, 3.245137946630484, 3.2677521483491634, 3.306196291270918, 5.235187697874265, 10.176390773405698, 14.203980099502488, 18.570782451379465, 19.043419267299864]
#
ttt = np.array(list_top_probabilities_of_classes_from_least_to_most_likely_in_training)
# Below 0.1 %
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[0:187], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[0:187], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[0:187], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[0:187], linestyle='--', marker='s', label="NN")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:187], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:187], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:187], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:187], linestyle='--', marker='s', label="NN")
# below 0.1%
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:273], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:273], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:273], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:273], linestyle='--', marker='s', label="NN")
# below 1%
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:306], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:306], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[19:306], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[19:306], linestyle='--', marker='s', label="NN")
# between 0.1 and 1
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[272:306], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[272:306], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[272:306], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[272:306], linestyle='--', marker='s', label="NN")
# above 1%
plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[306:], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[306:], linestyle='--', marker='s', label="LDA")
plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[306:], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[306:], linestyle='--', marker='s', label="NN")
#
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[311:], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[311:], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[311:], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[311:], linestyle='--', marker='s', label="NN")
#
# k = 300
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[k:], LDA_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[k:], linestyle='--', marker='s', label="LDA")
# plt.plot(list_top_probabilities_of_classes_from_least_to_most_likely_in_training[k:], NN_list_of_percentage_samples_not_corectly_classified_in_testing_data___for_each_class_sorted_from_least_likely_to_most_likely_in_training_data[k:], linestyle='--', marker='s', label="NN")
#
plt.ylabel("Missclassification Rate", fontsize=12)
plt.xlabel("Probability of class in training", fontsize=12)
plt.legend(fontsize=10)
plt.show()
5 + 6
#
#




